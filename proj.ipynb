{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74e1c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ccea6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  lepton pT  lepton eta  lepton phi  missing energy magnitude  \\\n",
      "0    1.0      0.908       0.329     0.35900                     1.500   \n",
      "1    1.0      0.799       1.470    -1.64000                     0.454   \n",
      "2    0.0      1.340      -0.877     0.93600                     1.990   \n",
      "3    1.0      1.110       0.321     1.52000                     0.883   \n",
      "4    0.0      1.600      -0.608     0.00707                     1.820   \n",
      "\n",
      "   missing energy phi  jet 1 pt  jet 1 eta jet 1 phi  jet 1 b-tag  ...  \\\n",
      "0              -0.313     1.100     -0.558     -1.59         2.17  ...   \n",
      "1               0.426     1.100      1.280      1.38         0.00  ...   \n",
      "2               0.882     1.790     -1.650    -0.942         0.00  ...   \n",
      "3              -1.210     0.681     -1.070    -0.922         0.00  ...   \n",
      "4              -0.112     0.848     -0.566      1.58         2.17  ...   \n",
      "\n",
      "   jet 4 eta  jet 4 phi  jet 4 b-tag   m_jj  m_jjj   m_lv  m_jlv   m_bb  \\\n",
      "0     -1.140  -0.000819          0.0  0.302  0.833  0.986  0.978  0.780   \n",
      "1      1.130   0.900000          0.0  0.910  1.110  0.986  0.951  0.803   \n",
      "2     -0.678  -1.360000          0.0  0.947  1.030  0.999  0.728  0.869   \n",
      "3     -0.374   0.113000          0.0  0.756  1.360  0.987  0.838  1.130   \n",
      "4     -0.654  -1.270000          3.1  0.824  0.938  0.972  0.789  0.431   \n",
      "\n",
      "   m_wbb  m_wwbb  \n",
      "0  0.992   0.798  \n",
      "1  0.866   0.780  \n",
      "2  1.030   0.958  \n",
      "3  0.872   0.808  \n",
      "4  0.961   0.958  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cl/vqr669317693_lc6y70yn19r0000gn/T/ipykernel_89050/3790264241.py:2: DtypeWarning: Columns (8,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('../HIGGS_train.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('../HIGGS_train.csv')\n",
    "\n",
    "#label the data columns with the following names: label, lepton pT, lepton eta, lepton phi, missing energy magnitude, missing energy phi, jet 1 pt, jet 1 eta, jet 1 phi, jet 1 b-tag, jet 2 pt, jet 2 eta, jet 2 phi, jet 2 b-tag, jet 3 pt, jet 3 eta, jet 3 phi, jet 3 b-tag, jet 4 pt, jet 4 eta, jet 4 phi, jet 4 b-tag, m_jj, m_jjj, m_lv, m_jlv, m_bb, m_wbb, m_wwbb\n",
    "data.columns = ['label', 'lepton pT', 'lepton eta', 'lepton phi', 'missing energy magnitude', 'missing energy phi', 'jet 1 pt', 'jet 1 eta', 'jet 1 phi', 'jet 1 b-tag', 'jet 2 pt', 'jet 2 eta', 'jet 2 phi', 'jet 2 b-tag', 'jet 3 pt', 'jet 3 eta', 'jet 3 phi', 'jet 3 b-tag', 'jet 4 pt', 'jet 4 eta', 'jet 4 phi', 'jet 4 b-tag', 'm_jj', 'm_jjj', 'm_lv', 'm_jlv', 'm_bb', 'm_wbb', 'm_wwbb']\n",
    "\n",
    "# Print the first five rows of the data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "007d97be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 260691 contains non-float values in columns: ['jet 3 b-tag']\n",
      "Row 261025 contains non-float values in columns: ['jet 1 phi']\n",
      "Row 490958 contains non-float values in columns: ['jet 4 b-tag']\n",
      "Row 490959 contains non-float values in columns: ['jet 4 b-tag']\n"
     ]
    }
   ],
   "source": [
    "# Find columns with non-float data types\n",
    "non_float_columns = data.select_dtypes(exclude=['float']).columns.tolist()\n",
    "\n",
    "# Convert non-float columns to numeric data type\n",
    "for col in non_float_columns:\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "# Find rows with non-float values\n",
    "nonfloat_rows = data[data.isnull().any(axis=1)]\n",
    "\n",
    "# Print the row numbers and column names with non-float values\n",
    "for index, row in nonfloat_rows.iterrows():\n",
    "    nonfloat_columns = row.index[row.isnull()].tolist()\n",
    "    print(f\"Row {index} contains non-float values in columns: {nonfloat_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e94fb359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.07504446 0.56769547 0.60316092 0.1514615  0.41005747\n",
      "  0.11661206 0.40606061 0.04310345 1.         0.05468408 0.46323024\n",
      "  0.86494253 1.         0.02861994 0.26923077 0.71034483 0.\n",
      "  0.00302626 0.272      0.49976466 0.         0.00878655 0.05178336\n",
      "  0.15336834 0.07937736 0.05361159 0.08477913 0.07564732]\n",
      " [1.         0.06212211 0.80246914 0.02873563 0.04579825 0.62241379\n",
      "  0.11661206 0.71548822 0.89655172 0.         0.05810183 0.76460481\n",
      "  0.26436782 1.         0.0884065  0.56520147 0.43994253 1.\n",
      "  0.07966177 0.726      0.75862069 0.         0.03618258 0.0761779\n",
      "  0.15336834 0.0767669  0.05529633 0.06927526 0.07260112]\n",
      " [0.         0.12625963 0.31954733 0.76896552 0.20095958 0.75344828\n",
      "  0.20033976 0.22222222 0.22931034 0.         0.1955131  0.3838488\n",
      "  0.71149425 1.         0.12563667 0.23809524 0.39511494 0.\n",
      "  0.03382287 0.3644     0.1091954  0.         0.03784977 0.06913254\n",
      "  0.15559903 0.05520642 0.06013082 0.0894549  0.10272466]\n",
      " [1.         0.09899229 0.56604938 0.93678161 0.08913432 0.15229885\n",
      "  0.06576872 0.31986532 0.23505747 0.         0.05363246 0.67525773\n",
      "  0.77902299 1.         0.04038322 0.43589744 0.68132184 0.\n",
      "  0.01023587 0.4252     0.53247126 0.         0.02924346 0.09819463\n",
      "  0.15353993 0.06584163 0.07924904 0.07001354 0.07733965]\n",
      " [0.         0.15708358 0.37489712 0.50203161 0.18378677 0.46781609\n",
      "  0.08603325 0.4047138  0.95402299 1.         0.04960126 0.6104811\n",
      "  0.91091954 0.         0.07979626 0.28205128 0.03448276 0.\n",
      "  0.02545616 0.3692     0.13505747 1.         0.03230748 0.06103038\n",
      "  0.15096606 0.06110413 0.02804738 0.08096469 0.10272466]]\n"
     ]
    }
   ],
   "source": [
    "#scale the data using the min-max scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale data\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Print first five rows of scaled data\n",
    "print(scaled_data[:5])\n",
    "\n",
    "data = pd.DataFrame(scaled_data, columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae808d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               label      lepton pT     lepton eta     lepton phi  \\\n",
      "count  599999.000000  599999.000000  599999.000000  599999.000000   \n",
      "mean        0.529286       0.085061       0.499977       0.500048   \n",
      "std         0.499142       0.066988       0.207378       0.288931   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.037463       0.348354       0.250000   \n",
      "50%         1.000000       0.068643       0.499788       0.500759   \n",
      "75%         1.000000       0.114404       0.651852       0.750000   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "       missing energy magnitude  missing energy phi       jet 1 pt  \\\n",
      "count             599999.000000       599999.000000  599999.000000   \n",
      "mean                   0.100753            0.499668       0.103282   \n",
      "std                    0.060537            0.289297       0.057593   \n",
      "min                    0.000000            0.000000       0.000000   \n",
      "25%                    0.058223            0.249138       0.065526   \n",
      "50%                    0.089942            0.499448       0.091615   \n",
      "75%                    0.130248            0.750575       0.125106   \n",
      "max                    1.000000            1.000000       1.000000   \n",
      "\n",
      "           jet 1 eta      jet 1 phi    jet 1 b-tag  ...      jet 4 eta  \\\n",
      "count  599999.000000  599998.000000  599999.000000  ...  599999.000000   \n",
      "mean        0.499631       0.500147       0.461005  ...       0.499938   \n",
      "std         0.170084       0.289251       0.473024  ...       0.201630   \n",
      "min         0.000000       0.000000       0.000000  ...       0.000000   \n",
      "25%         0.384007       0.250575       0.000000  ...       0.357000   \n",
      "50%         0.499495       0.499698       0.502304  ...       0.499908   \n",
      "75%         0.615320       0.750000       1.000000  ...       0.643000   \n",
      "max         1.000000       1.000000       1.000000  ...       1.000000   \n",
      "\n",
      "           jet 4 phi    jet 4 b-tag           m_jj          m_jjj  \\\n",
      "count  599999.000000  599997.000000  599999.000000  599999.000000   \n",
      "mean        0.499388       0.321426       0.041772       0.068641   \n",
      "std         0.288955       0.450939       0.030164       0.033297   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.249425       0.000000       0.030821       0.052928   \n",
      "50%         0.498330       0.000000       0.035507       0.062087   \n",
      "75%         0.749425       1.000000       0.041139       0.073536   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "                m_lv          m_jlv           m_bb          m_wbb  \\\n",
      "count  599999.000000  599999.000000  599999.000000  599999.000000   \n",
      "mean        0.164459       0.082484       0.067774       0.089843   \n",
      "std         0.028217       0.038524       0.038448       0.044850   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.153368       0.059074       0.045847       0.063492   \n",
      "50%         0.154055       0.073480       0.060424       0.079242   \n",
      "75%         0.159202       0.095040       0.079982       0.102990   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "              m_wwbb  \n",
      "count  599999.000000  \n",
      "mean        0.103035  \n",
      "std         0.052982  \n",
      "min         0.000000  \n",
      "25%         0.070909  \n",
      "50%         0.088171  \n",
      "75%         0.119986  \n",
      "max         1.000000  \n",
      "\n",
      "[8 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4cbfb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows with non-float values\n",
    "data.drop(nonfloat_rows.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4638089",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79658 outlier rows removed.\n"
     ]
    }
   ],
   "source": [
    "# Calculate z-scores for each column\n",
    "z_scores = np.abs((data - data.mean()) / data.std())\n",
    "\n",
    "# Define threshold for z-scores\n",
    "z_threshold = 3\n",
    "\n",
    "# Remove rows with z-score greater than threshold in any column\n",
    "outlier_rows = data[(z_scores > z_threshold).any(axis=1)]\n",
    "data = data[(z_scores <= z_threshold).all(axis=1)]\n",
    "\n",
    "# Print number of outlier rows removed\n",
    "print(f\"{len(outlier_rows)} outlier rows removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77698f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a code that finds the correlated columns and removes them\n",
    "# Find columns with correlation greater than threshold\n",
    "correlation_threshold = 0.8\n",
    "correlated_columns = set()\n",
    "correlation_matrix = data.corr()\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > correlation_threshold:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_columns.add(colname)\n",
    "        \n",
    "# Drop correlated columns\n",
    "data.drop(labels=correlated_columns, axis=1, inplace=True)\n",
    "\n",
    "# Print number of correlated columns removed\n",
    "print(f\"{len(correlated_columns)} correlated columns removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "687ad543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  lepton pT  lepton eta  lepton phi  missing energy magnitude  \\\n",
      "0    1.0   0.075044    0.567695    0.603161                  0.151461   \n",
      "1    1.0   0.062122    0.802469    0.028736                  0.045798   \n",
      "2    0.0   0.126260    0.319547    0.768966                  0.200960   \n",
      "3    1.0   0.098992    0.566049    0.936782                  0.089134   \n",
      "4    0.0   0.157084    0.374897    0.502032                  0.183787   \n",
      "\n",
      "   missing energy phi  jet 1 pt  jet 1 eta  jet 1 phi  jet 1 b-tag  ...  \\\n",
      "0            0.410057  0.116612   0.406061   0.043103          1.0  ...   \n",
      "1            0.622414  0.116612   0.715488   0.896552          0.0  ...   \n",
      "2            0.753448  0.200340   0.222222   0.229310          0.0  ...   \n",
      "3            0.152299  0.065769   0.319865   0.235057          0.0  ...   \n",
      "4            0.467816  0.086033   0.404714   0.954023          1.0  ...   \n",
      "\n",
      "   jet 4 b-tag      m_jj     m_jjj      m_lv     m_jlv      m_bb     m_wbb  \\\n",
      "0          0.0  0.008787  0.051783  0.153368  0.079377  0.053612  0.084779   \n",
      "1          0.0  0.036183  0.076178  0.153368  0.076767  0.055296  0.069275   \n",
      "2          0.0  0.037850  0.069133  0.155599  0.055206  0.060131  0.089455   \n",
      "3          0.0  0.029243  0.098195  0.153540  0.065842  0.079249  0.070014   \n",
      "4          1.0  0.032307  0.061030  0.150966  0.061104  0.028047  0.080965   \n",
      "\n",
      "     m_wwbb  Delta phi jet 1 jet 2  Delta eta jet 1 jet 2  \n",
      "0  0.075647               0.821839               0.057170  \n",
      "1  0.072601               0.632184               0.049117  \n",
      "2  0.102725               0.482184               0.161627  \n",
      "3  0.077340               0.543966               0.355392  \n",
      "4  0.102725               0.043103               0.205767  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "#  data['m_bb^2']=data['m_bb']**2\n",
    "# Add new features\n",
    "data['Delta phi jet 1 jet 2'] = abs(data['jet 1 phi'] - data['jet 2 phi'])\n",
    "data['Delta eta jet 1 jet 2'] = abs(data['jet 1 eta'] - data['jet 2 eta'])\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3eecfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label  lepton pT  lepton eta  lepton phi  missing energy magnitude  \\\n",
      "0  0.352032   0.066680    0.980579    0.539973                  0.074649   \n",
      "1  0.178451  -0.008291    0.756576    0.694435                  0.015624   \n",
      "2  0.742430   0.128053    0.839088    0.269355                  0.098904   \n",
      "3  0.811036   0.141719    0.272623    0.269545                  0.187036   \n",
      "4 -0.083634   0.069182    0.400144    0.635856                  0.054877   \n",
      "\n",
      "   missing energy phi  jet 1 pt  jet 1 eta  jet 1 phi  jet 1 b-tag  ...  \\\n",
      "0            0.298599  0.131689   0.452315   0.411172     0.698258  ...   \n",
      "1            0.545230  0.121336   0.573704   0.809893     0.354138  ...   \n",
      "2            1.061601  0.107931   0.604443   0.550602     0.275448  ...   \n",
      "3            0.639859  0.247526   0.311638   0.524287     0.377738  ...   \n",
      "4            0.698716  0.080684   0.486719   0.359486     0.297999  ...   \n",
      "\n",
      "   jet 4 b-tag      m_jj     m_jjj      m_lv     m_jlv      m_bb     m_wbb  \\\n",
      "0    -0.694628  0.058009  0.093760  0.168279  0.049018  0.064624  0.168437   \n",
      "1     0.616178  0.073823  0.105054  0.100873  0.114260  0.069366  0.055788   \n",
      "2    -0.191124  0.054363  0.126309  0.197943  0.049883  0.045915  0.020967   \n",
      "3     0.830035  0.017918  0.092034  0.131685  0.023570  0.083068  0.068948   \n",
      "4     0.546212  0.035441  0.089288  0.163473  0.078124  0.086274  0.109276   \n",
      "\n",
      "     m_wwbb  Delta phi jet 1 jet 2  Delta eta jet 1 jet 2  \n",
      "0  0.041824               0.419095               0.114108  \n",
      "1  0.056379               0.457234               0.240349  \n",
      "2  0.082783               0.161064               0.119929  \n",
      "3  0.197614               0.213902               0.160514  \n",
      "4  0.075541               0.149286               0.042589  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "synthetic_data = pd.DataFrame(columns=data.columns)\n",
    "for col in data.columns:\n",
    "    synthetic_data[col] = np.random.normal(data[col].mean(), data[col].std(), len(data))\n",
    "\n",
    "# Print the first five rows of the synthetic data\n",
    "print(synthetic_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b116d996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.64065355918644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = data.iloc[:, 1:]\n",
    "y = data.iloc[:, 0]\n",
    "\n",
    "#shuffle the data\n",
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(X, y, random_state=0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Create the logistic regression model\n",
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "predictions = logistic_regression_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffeccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# apply k-fold cross validation\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores = []\n",
    "\n",
    "for train_indices, test_indices in k_fold.split(X):\n",
    "    # split data into training and testing sets\n",
    "    X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
    "    y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "    \n",
    "    # create and train the model\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # evaluate the model on the testing set\n",
    "    score = model.score(X_test, y_test)\n",
    "    scores.append(score)\n",
    "\n",
    "# print the accuracy of each fold\n",
    "print(scores)\n",
    "\n",
    "# print the average accuracy of all 10 folds\n",
    "print(np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3bec00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#perform regularized logistic regression on different values of C\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create and train the model\n",
    "model = LogisticRegression(C=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# print the accuracy for the model\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd878c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform xgboost on the dataset\n",
    "import xgboost as xgb\n",
    "\n",
    "# create the DMatrix\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "# create the parameter dictionary\n",
    "params = {'max_depth': 2, 'eta': 1, 'objective': 'binary:logistic'}\n",
    "\n",
    "# train the model\n",
    "num_rounds = 2\n",
    "bst = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "# create the DMatrix for the testing data\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "# make predictions\n",
    "predictions = bst.predict(dtest)\n",
    "\n",
    "# print the first 4 predictions\n",
    "print(predictions[:4])\n",
    "\n",
    "# print the first 4 actual labels\n",
    "print(y_test[:4])\n",
    "\n",
    "# print the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions.round())\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ba40d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree accuracy: 0.6351936554304237\n",
      "Forest accuracy: 0.724391743859784\n"
     ]
    }
   ],
   "source": [
    "#implementing a decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# create the model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# print the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Tree accuracy:\", accuracy)\n",
    "\n",
    "#implementing a random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create the model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# print the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Forest accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98164491",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing a gradient boosted tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# create the model\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# print the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Gradient Boosted Tree accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7fea2540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 0.7514690616101106\n",
      "Testing accuracy: 0.7454819193439963\n"
     ]
    }
   ],
   "source": [
    "# Implementing a neural network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "activations = ['identity', 'logistic', 'tanh', 'relu']\n",
    "solvers = ['lbfgs', 'sgd', 'adam']\n",
    "\n",
    "# create the model\n",
    "model = MLPClassifier(hidden_layer_sizes=(40, 35, 30, 25), max_iter=500)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Training set accuracy:\", model.score(X_train, y_train))\n",
    "print(f\"Testing accuracy:\", accuracy)\n",
    "\n",
    "#save the model using pickle\n",
    "import pickle\n",
    "\n",
    "s = pickle.dumps(model)\n",
    "saved_model = pickle.loads(s)\n",
    "\n",
    "best_weights=model.coefs_\n",
    "best_biases=model.intercepts_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159441eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, BatchNormalization \n",
    "from keras import Sequential\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras import regularizers  # Added import for regularizers\n",
    "\n",
    "'''Write your code here'''\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Dense(200, activation='relu'),  # Increased neurons to 128\n",
    "    BatchNormalization(),\n",
    "    Dense(100, activation='relu'),  # Increased neurons to 64\n",
    "    BatchNormalization(),\n",
    "    Dense(28, activation='relu'),  # Increased neurons to 32\n",
    "    BatchNormalization(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model with appropriate loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the test accuracy\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ac52d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74e1c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ccea6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  lepton pT  lepton eta  lepton phi  missing energy magnitude  \\\n",
      "0    1.0      0.908       0.329     0.35900                     1.500   \n",
      "1    1.0      0.799       1.470    -1.64000                     0.454   \n",
      "2    0.0      1.340      -0.877     0.93600                     1.990   \n",
      "3    1.0      1.110       0.321     1.52000                     0.883   \n",
      "4    0.0      1.600      -0.608     0.00707                     1.820   \n",
      "\n",
      "   missing energy phi  jet 1 pt  jet 1 eta jet 1 phi  jet 1 b-tag  ...  \\\n",
      "0              -0.313     1.100     -0.558     -1.59         2.17  ...   \n",
      "1               0.426     1.100      1.280      1.38         0.00  ...   \n",
      "2               0.882     1.790     -1.650    -0.942         0.00  ...   \n",
      "3              -1.210     0.681     -1.070    -0.922         0.00  ...   \n",
      "4              -0.112     0.848     -0.566      1.58         2.17  ...   \n",
      "\n",
      "   jet 4 eta  jet 4 phi  jet 4 b-tag   m_jj  m_jjj   m_lv  m_jlv   m_bb  \\\n",
      "0     -1.140  -0.000819          0.0  0.302  0.833  0.986  0.978  0.780   \n",
      "1      1.130   0.900000          0.0  0.910  1.110  0.986  0.951  0.803   \n",
      "2     -0.678  -1.360000          0.0  0.947  1.030  0.999  0.728  0.869   \n",
      "3     -0.374   0.113000          0.0  0.756  1.360  0.987  0.838  1.130   \n",
      "4     -0.654  -1.270000          3.1  0.824  0.938  0.972  0.789  0.431   \n",
      "\n",
      "   m_wbb  m_wwbb  \n",
      "0  0.992   0.798  \n",
      "1  0.866   0.780  \n",
      "2  1.030   0.958  \n",
      "3  0.872   0.808  \n",
      "4  0.961   0.958  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cl/vqr669317693_lc6y70yn19r0000gn/T/ipykernel_36568/3790264241.py:2: DtypeWarning: Columns (8,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('../HIGGS_train.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('../HIGGS_train.csv')\n",
    "\n",
    "#label the data columns with the following names: label, lepton pT, lepton eta, lepton phi, missing energy magnitude, missing energy phi, jet 1 pt, jet 1 eta, jet 1 phi, jet 1 b-tag, jet 2 pt, jet 2 eta, jet 2 phi, jet 2 b-tag, jet 3 pt, jet 3 eta, jet 3 phi, jet 3 b-tag, jet 4 pt, jet 4 eta, jet 4 phi, jet 4 b-tag, m_jj, m_jjj, m_lv, m_jlv, m_bb, m_wbb, m_wwbb\n",
    "data.columns = ['label', 'lepton pT', 'lepton eta', 'lepton phi', 'missing energy magnitude', 'missing energy phi', 'jet 1 pt', 'jet 1 eta', 'jet 1 phi', 'jet 1 b-tag', 'jet 2 pt', 'jet 2 eta', 'jet 2 phi', 'jet 2 b-tag', 'jet 3 pt', 'jet 3 eta', 'jet 3 phi', 'jet 3 b-tag', 'jet 4 pt', 'jet 4 eta', 'jet 4 phi', 'jet 4 b-tag', 'm_jj', 'm_jjj', 'm_lv', 'm_jlv', 'm_bb', 'm_wbb', 'm_wwbb']\n",
    "\n",
    "# Print the first five rows of the data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "007d97be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 260691 contains non-float values in columns: ['jet 3 b-tag']\n",
      "Row 261025 contains non-float values in columns: ['jet 1 phi']\n",
      "Row 490958 contains non-float values in columns: ['jet 4 b-tag']\n",
      "Row 490959 contains non-float values in columns: ['jet 4 b-tag']\n"
     ]
    }
   ],
   "source": [
    "# Find columns with non-float data types\n",
    "non_float_columns = data.select_dtypes(exclude=['float']).columns.tolist()\n",
    "\n",
    "# Convert non-float columns to numeric data type\n",
    "for col in non_float_columns:\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "# Find rows with non-float values\n",
    "nonfloat_rows = data[data.isnull().any(axis=1)]\n",
    "\n",
    "# Print the row numbers and column names with non-float values\n",
    "for index, row in nonfloat_rows.iterrows():\n",
    "    nonfloat_columns = row.index[row.isnull()].tolist()\n",
    "    print(f\"Row {index} contains non-float values in columns: {nonfloat_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4cbfb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows with non-float values\n",
    "data.drop(nonfloat_rows.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "687ad543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  lepton pT  lepton eta  lepton phi  missing energy magnitude  \\\n",
      "0    1.0      0.908       0.329     0.35900                     1.500   \n",
      "1    1.0      0.799       1.470    -1.64000                     0.454   \n",
      "2    0.0      1.340      -0.877     0.93600                     1.990   \n",
      "3    1.0      1.110       0.321     1.52000                     0.883   \n",
      "4    0.0      1.600      -0.608     0.00707                     1.820   \n",
      "\n",
      "   missing energy phi  jet 1 pt  jet 1 eta  jet 1 phi  jet 1 b-tag  ...  \\\n",
      "0              -0.313     1.100     -0.558     -1.590         2.17  ...   \n",
      "1               0.426     1.100      1.280      1.380         0.00  ...   \n",
      "2               0.882     1.790     -1.650     -0.942         0.00  ...   \n",
      "3              -1.210     0.681     -1.070     -0.922         0.00  ...   \n",
      "4              -0.112     0.848     -0.566      1.580         2.17  ...   \n",
      "\n",
      "   m_wbb  m_wwbb  b-tag sum  jet pt sum  jet eta sum  jet phi sum  \\\n",
      "0  0.992   0.798       4.38       2.812       -3.172     0.411181   \n",
      "1  0.866   0.780       4.76       4.205        4.306     1.251000   \n",
      "2  1.030   0.958       2.21       6.255       -4.434    -1.931000   \n",
      "3  0.872   0.808       2.21       2.559       -0.774     0.793000   \n",
      "4  0.961   0.958       5.27       3.176       -1.767     0.120000   \n",
      "\n",
      "   lepton pt sum  lepton eta sum  lepton phi sum    m_bb^2  \n",
      "0          1.816           0.658         0.71800  0.608400  \n",
      "1          1.598           2.940        -3.28000  0.644809  \n",
      "2          2.680          -1.754         1.87200  0.755161  \n",
      "3          2.220           0.642         3.04000  1.276900  \n",
      "4          3.200          -1.216         0.01414  0.185761  \n",
      "\n",
      "[5 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "#add a column to the dataset that is the sum of the b-tags for the four jets\n",
    "data['b-tag sum'] = data['jet 1 b-tag'] + data['jet 2 b-tag'] + data['jet 3 b-tag'] + data['jet 4 b-tag']\n",
    "\n",
    "#add a column to the dataset that is the sum of the pt values for the four jets\n",
    "data['jet pt sum'] = data['jet 1 pt'] + data['jet 2 pt'] + data['jet 3 pt'] + data['jet 4 pt']\n",
    "\n",
    "#add a column to the dataset that is the sum of the eta values for the four jets\n",
    "data['jet eta sum'] = data['jet 1 eta'] + data['jet 2 eta'] + data['jet 3 eta'] + data['jet 4 eta']\n",
    "\n",
    "#add a column to the dataset that is the sum of the phi values for the four jets\n",
    "data['jet phi sum'] = data['jet 1 phi'] + data['jet 2 phi'] + data['jet 3 phi'] + data['jet 4 phi']\n",
    "\n",
    "#add a column to the dataset that is the sum of the pt values for the two leptons\n",
    "data['lepton pt sum'] = data['lepton pT'] + data['lepton pT']\n",
    "\n",
    "#add a column to the dataset that is the sum of the eta values for the two leptons\n",
    "data['lepton eta sum'] = data['lepton eta'] + data['lepton eta']\n",
    "\n",
    "#add a column to the dataset that is the sum of the phi values for the two leptons\n",
    "data['lepton phi sum'] = data['lepton phi'] + data['lepton phi']\n",
    "\n",
    "#add a column containg the sqaure of the m_bb column\n",
    "data['m_bb^2'] = data['m_bb']**2\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4638089",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289558 outlier rows removed.\n"
     ]
    }
   ],
   "source": [
    "# Calculate z-scores for each column\n",
    "z_scores = np.abs((data - data.mean()) / data.std())\n",
    "\n",
    "# Define threshold for z-scores\n",
    "z_threshold = 2\n",
    "\n",
    "# Remove rows with z-score greater than threshold in any column\n",
    "outlier_rows = data[(z_scores > z_threshold).any(axis=1)]\n",
    "data = data[(z_scores <= z_threshold).all(axis=1)]\n",
    "\n",
    "# Print number of outlier rows removed\n",
    "print(f\"{len(outlier_rows)} outlier rows removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b116d996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6621462010909247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = data.iloc[:, 1:]\n",
    "y = data.iloc[:, 0]\n",
    "\n",
    "#shuffle the data\n",
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(X, y, random_state=0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Create the logistic regression model\n",
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "predictions = logistic_regression_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ffeccd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.663574281664734, 0.661899239788687, 0.663606494008504, 0.6642185285401366, 0.6666666666666666, 0.6656358716660224, 0.6671176394794486, 0.6592146377605257, 0.6660116612440808, 0.6652385400895532]\n",
      "0.6643183560908359\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# apply k-fold cross validation\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores = []\n",
    "\n",
    "for train_indices, test_indices in k_fold.split(X):\n",
    "    # split data into training and testing sets\n",
    "    X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
    "    y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "    \n",
    "    # create and train the model\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # evaluate the model on the testing set\n",
    "    score = model.score(X_test, y_test)\n",
    "    scores.append(score)\n",
    "\n",
    "# print the accuracy of each fold\n",
    "print(scores)\n",
    "\n",
    "# print the average accuracy of all 10 folds\n",
    "print(np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb3bec00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6641754985020778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#perform regularized logistic regression on different values of C\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create and train the model\n",
    "model = LogisticRegression(C=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# print the accuracy for the model\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd878c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28494623 0.7900954  0.63004136 0.42988688]\n",
      "416164    1.0\n",
      "405934    0.0\n",
      "585712    1.0\n",
      "52731     0.0\n",
      "Name: label, dtype: float64\n",
      "Accuracy: 0.6616950681313017\n"
     ]
    }
   ],
   "source": [
    "#perform xgboost on the dataset\n",
    "import xgboost as xgb\n",
    "\n",
    "# create the DMatrix\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "# create the parameter dictionary\n",
    "params = {'max_depth': 2, 'eta': 1, 'objective': 'binary:logistic'}\n",
    "\n",
    "# train the model\n",
    "num_rounds = 2\n",
    "bst = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "# create the DMatrix for the testing data\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "# make predictions\n",
    "predictions = bst.predict(dtest)\n",
    "\n",
    "# print the first 4 predictions\n",
    "print(predictions[:4])\n",
    "\n",
    "# print the first 4 actual labels\n",
    "print(y_test[:4])\n",
    "\n",
    "# print the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions.round())\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ba40d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree accuracy: 0.6335727861353606\n",
      "Forest accuracy: 0.7269271655445673\n"
     ]
    }
   ],
   "source": [
    "#implementing a decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# create the model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# print the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Tree accuracy:\", accuracy)\n",
    "\n",
    "#implementing a random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create the model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# print the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Forest accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98164491",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing a gradient boosted tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# create the model\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# print the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Gradient Boosted Tree accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fea2540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

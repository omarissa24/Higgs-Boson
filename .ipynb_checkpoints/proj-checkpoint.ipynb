{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74e1c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ccea6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cl/vqr669317693_lc6y70yn19r0000gn/T/ipykernel_35472/963441557.py:2: DtypeWarning: Columns (8,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('../HIGGS_train.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('../HIGGS_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "007d97be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 260691 contains non-float values in columns: ['0.00E+00.1']\n",
      "Row 261025 contains non-float values in columns: ['-1.09E+00']\n",
      "Row 490958 contains non-float values in columns: ['3.10E+00']\n",
      "Row 490959 contains non-float values in columns: ['3.10E+00']\n"
     ]
    }
   ],
   "source": [
    "# Find columns with non-float data types\n",
    "non_float_columns = data.select_dtypes(exclude=['float']).columns.tolist()\n",
    "\n",
    "# Convert non-float columns to numeric data type\n",
    "for col in non_float_columns:\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "# Find rows with non-float values\n",
    "nonfloat_rows = data[data.isnull().any(axis=1)]\n",
    "\n",
    "# Print the row numbers and column names with non-float values\n",
    "for index, row in nonfloat_rows.iterrows():\n",
    "    nonfloat_columns = row.index[row.isnull()].tolist()\n",
    "    print(f\"Row {index} contains non-float values in columns: {nonfloat_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4cbfb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows with non-float values\n",
    "data.drop(nonfloat_rows.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4638089",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261922 outlier rows removed.\n"
     ]
    }
   ],
   "source": [
    "# Calculate z-scores for each column\n",
    "z_scores = np.abs((data - data.mean()) / data.std())\n",
    "\n",
    "# Define threshold for z-scores\n",
    "z_threshold = 2\n",
    "\n",
    "# Remove rows with z-score greater than threshold in any column\n",
    "outlier_rows = data[(z_scores > z_threshold).any(axis=1)]\n",
    "data = data[(z_scores <= z_threshold).all(axis=1)]\n",
    "\n",
    "# Print number of outlier rows removed\n",
    "print(f\"{len(outlier_rows)} outlier rows removed.\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b116d996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6500069018556132\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = data.iloc[:, 1:]\n",
    "y = data.iloc[:, 0]\n",
    "\n",
    "#shuffle the data\n",
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(X, y, random_state=0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Create the logistic regression model\n",
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "predictions = logistic_regression_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ffeccd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6525970184571699, 0.6483968291528632, 0.6483376715570279, 0.6520543082793504, 0.651640192859467, 0.6492146596858639, 0.6509598603839442, 0.6457538379625521, 0.649835832815689, 0.6508415416925489]\n",
      "0.6499631752846476\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# apply k-fold cross validation\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores = []\n",
    "\n",
    "for train_indices, test_indices in k_fold.split(X):\n",
    "    # split data into training and testing sets\n",
    "    X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
    "    y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "    \n",
    "    # create and train the model\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # evaluate the model on the testing set\n",
    "    score = model.score(X_test, y_test)\n",
    "    scores.append(score)\n",
    "\n",
    "# print the accuracy of each fold\n",
    "print(scores)\n",
    "\n",
    "# print the average accuracy of all 10 folds\n",
    "print(np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb3bec00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6508415416925489\n"
     ]
    }
   ],
   "source": [
    "#perform regularized logistic regression on different values of C\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create and train the model\n",
    "model = LogisticRegression(C=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# print the accuracy for the model\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd878c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4718679 0.4375873 0.4718679 0.4375873]\n",
      "479793    0.0\n",
      "401597    0.0\n",
      "399550    1.0\n",
      "424447    1.0\n",
      "Name: 1.00E+00, dtype: float64\n",
      "Accuracy: 0.6585914159789392\n"
     ]
    }
   ],
   "source": [
    "#perform xgboost on the dataset\n",
    "import xgboost as xgb\n",
    "\n",
    "# create the DMatrix\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "# create the parameter dictionary\n",
    "params = {'max_depth': 2, 'eta': 1, 'objective': 'binary:logistic'}\n",
    "\n",
    "# train the model\n",
    "num_rounds = 2\n",
    "bst = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "# create the DMatrix for the testing data\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "# make predictions\n",
    "predictions = bst.predict(dtest)\n",
    "\n",
    "# print the first 4 predictions\n",
    "print(predictions[:4])\n",
    "\n",
    "# print the first 4 actual labels\n",
    "print(y_test[:4])\n",
    "\n",
    "# print the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions.round())\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ba40d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree accuracy: 0.6371461531635461\n",
      "Forest accuracy: 0.7240512319933742\n"
     ]
    }
   ],
   "source": [
    "#implementing a decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# create the model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# print the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Tree accuracy:\", accuracy)\n",
    "\n",
    "#implementing a random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create the model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# print the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Forest accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98164491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosted Tree accuracy: 0.7101783654272784\n"
     ]
    }
   ],
   "source": [
    "#implementing a gradient boosted tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# create the model\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# print the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Gradient Boosted Tree accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

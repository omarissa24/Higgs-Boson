{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74e1c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ccea6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  lepton pT  lepton eta  lepton phi  missing energy magnitude  \\\n",
      "0    1.0      0.908       0.329     0.35900                     1.500   \n",
      "1    1.0      0.799       1.470    -1.64000                     0.454   \n",
      "2    0.0      1.340      -0.877     0.93600                     1.990   \n",
      "3    1.0      1.110       0.321     1.52000                     0.883   \n",
      "4    0.0      1.600      -0.608     0.00707                     1.820   \n",
      "\n",
      "   missing energy phi  jet 1 pt  jet 1 eta jet 1 phi  jet 1 b-tag  ...  \\\n",
      "0              -0.313     1.100     -0.558     -1.59         2.17  ...   \n",
      "1               0.426     1.100      1.280      1.38         0.00  ...   \n",
      "2               0.882     1.790     -1.650    -0.942         0.00  ...   \n",
      "3              -1.210     0.681     -1.070    -0.922         0.00  ...   \n",
      "4              -0.112     0.848     -0.566      1.58         2.17  ...   \n",
      "\n",
      "   jet 4 eta  jet 4 phi  jet 4 b-tag   m_jj  m_jjj   m_lv  m_jlv   m_bb  \\\n",
      "0     -1.140  -0.000819          0.0  0.302  0.833  0.986  0.978  0.780   \n",
      "1      1.130   0.900000          0.0  0.910  1.110  0.986  0.951  0.803   \n",
      "2     -0.678  -1.360000          0.0  0.947  1.030  0.999  0.728  0.869   \n",
      "3     -0.374   0.113000          0.0  0.756  1.360  0.987  0.838  1.130   \n",
      "4     -0.654  -1.270000          3.1  0.824  0.938  0.972  0.789  0.431   \n",
      "\n",
      "   m_wbb  m_wwbb  \n",
      "0  0.992   0.798  \n",
      "1  0.866   0.780  \n",
      "2  1.030   0.958  \n",
      "3  0.872   0.808  \n",
      "4  0.961   0.958  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cl/vqr669317693_lc6y70yn19r0000gn/T/ipykernel_88418/3790264241.py:2: DtypeWarning: Columns (8,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('../HIGGS_train.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('../HIGGS_train.csv')\n",
    "\n",
    "#label the data columns with the following names: label, lepton pT, lepton eta, lepton phi, missing energy magnitude, missing energy phi, jet 1 pt, jet 1 eta, jet 1 phi, jet 1 b-tag, jet 2 pt, jet 2 eta, jet 2 phi, jet 2 b-tag, jet 3 pt, jet 3 eta, jet 3 phi, jet 3 b-tag, jet 4 pt, jet 4 eta, jet 4 phi, jet 4 b-tag, m_jj, m_jjj, m_lv, m_jlv, m_bb, m_wbb, m_wwbb\n",
    "data.columns = ['label', 'lepton pT', 'lepton eta', 'lepton phi', 'missing energy magnitude', 'missing energy phi', 'jet 1 pt', 'jet 1 eta', 'jet 1 phi', 'jet 1 b-tag', 'jet 2 pt', 'jet 2 eta', 'jet 2 phi', 'jet 2 b-tag', 'jet 3 pt', 'jet 3 eta', 'jet 3 phi', 'jet 3 b-tag', 'jet 4 pt', 'jet 4 eta', 'jet 4 phi', 'jet 4 b-tag', 'm_jj', 'm_jjj', 'm_lv', 'm_jlv', 'm_bb', 'm_wbb', 'm_wwbb']\n",
    "\n",
    "# Print the first five rows of the data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "007d97be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 260691 contains non-float values in columns: ['jet 3 b-tag']\n",
      "Row 261025 contains non-float values in columns: ['jet 1 phi']\n",
      "Row 490958 contains non-float values in columns: ['jet 4 b-tag']\n",
      "Row 490959 contains non-float values in columns: ['jet 4 b-tag']\n"
     ]
    }
   ],
   "source": [
    "# Find columns with non-float data types\n",
    "non_float_columns = data.select_dtypes(exclude=['float']).columns.tolist()\n",
    "\n",
    "# Convert non-float columns to numeric data type\n",
    "for col in non_float_columns:\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "# Find rows with non-float values\n",
    "nonfloat_rows = data[data.isnull().any(axis=1)]\n",
    "\n",
    "# Print the row numbers and column names with non-float values\n",
    "for index, row in nonfloat_rows.iterrows():\n",
    "    nonfloat_columns = row.index[row.isnull()].tolist()\n",
    "    print(f\"Row {index} contains non-float values in columns: {nonfloat_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4cbfb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows with non-float values\n",
    "data.drop(nonfloat_rows.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4638089",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79658 outlier rows removed.\n"
     ]
    }
   ],
   "source": [
    "# Calculate z-scores for each column\n",
    "z_scores = np.abs((data - data.mean()) / data.std())\n",
    "\n",
    "# Define threshold for z-scores\n",
    "z_threshold = 3\n",
    "\n",
    "# Remove rows with z-score greater than threshold in any column\n",
    "outlier_rows = data[(z_scores > z_threshold).any(axis=1)]\n",
    "data = data[(z_scores <= z_threshold).all(axis=1)]\n",
    "\n",
    "# Print number of outlier rows removed\n",
    "print(f\"{len(outlier_rows)} outlier rows removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77698f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 correlated columns removed.\n"
     ]
    }
   ],
   "source": [
    "#write a code that finds the correlated columns and removes them\n",
    "# Find columns with correlation greater than threshold\n",
    "correlation_threshold = 0.8\n",
    "correlated_columns = set()\n",
    "correlation_matrix = data.corr()\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > correlation_threshold:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_columns.add(colname)\n",
    "        \n",
    "# Drop correlated columns\n",
    "data.drop(labels=correlated_columns, axis=1, inplace=True)\n",
    "\n",
    "# Print number of correlated columns removed\n",
    "print(f\"{len(correlated_columns)} correlated columns removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "687ad543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  lepton pT  lepton eta  lepton phi  missing energy magnitude  \\\n",
      "0    1.0      0.908       0.329     0.35900                     1.500   \n",
      "1    1.0      0.799       1.470    -1.64000                     0.454   \n",
      "2    0.0      1.340      -0.877     0.93600                     1.990   \n",
      "3    1.0      1.110       0.321     1.52000                     0.883   \n",
      "4    0.0      1.600      -0.608     0.00707                     1.820   \n",
      "\n",
      "   missing energy phi  jet 1 pt  jet 1 eta  jet 1 phi  jet 1 b-tag  ...  \\\n",
      "0              -0.313     1.100     -0.558     -1.590         2.17  ...   \n",
      "1               0.426     1.100      1.280      1.380         0.00  ...   \n",
      "2               0.882     1.790     -1.650     -0.942         0.00  ...   \n",
      "3              -1.210     0.681     -1.070     -0.922         0.00  ...   \n",
      "4              -0.112     0.848     -0.566      1.580         2.17  ...   \n",
      "\n",
      "   jet 4 phi  jet 4 b-tag   m_jj  m_jjj   m_lv  m_jlv   m_bb  m_wbb  \\\n",
      "0  -0.000819          0.0  0.302  0.833  0.986  0.978  0.780  0.992   \n",
      "1   0.900000          0.0  0.910  1.110  0.986  0.951  0.803  0.866   \n",
      "2  -1.360000          0.0  0.947  1.030  0.999  0.728  0.869  1.030   \n",
      "3   0.113000          0.0  0.756  1.360  0.987  0.838  1.130  0.872   \n",
      "4  -1.270000          3.1  0.824  0.938  0.972  0.789  0.431  0.961   \n",
      "\n",
      "   Delta phi jet 1 jet 2  Delta eta jet 1 jet 2  \n",
      "0                  2.860                  0.344  \n",
      "1                  2.200                  0.260  \n",
      "2                  1.678                  0.974  \n",
      "3                  1.893                  2.090  \n",
      "4                  0.150                  1.209  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "#  data['m_bb^2']=data['m_bb']**2\n",
    "# Add new features\n",
    "data['Delta phi jet 1 jet 2'] = abs(data['jet 1 phi'] - data['jet 2 phi'])\n",
    "data['Delta eta jet 1 jet 2'] = abs(data['jet 1 eta'] - data['jet 2 eta'])\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b116d996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6042523478238587\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = data.iloc[:, 1:]\n",
    "y = data.iloc[:, 0]\n",
    "\n",
    "#shuffle the data\n",
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(X, y, random_state=0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Create the logistic regression model\n",
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "predictions = logistic_regression_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffeccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# apply k-fold cross validation\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores = []\n",
    "\n",
    "for train_indices, test_indices in k_fold.split(X):\n",
    "    # split data into training and testing sets\n",
    "    X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
    "    y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "    \n",
    "    # create and train the model\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # evaluate the model on the testing set\n",
    "    score = model.score(X_test, y_test)\n",
    "    scores.append(score)\n",
    "\n",
    "# print the accuracy of each fold\n",
    "print(scores)\n",
    "\n",
    "# print the average accuracy of all 10 folds\n",
    "print(np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3bec00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#perform regularized logistic regression on different values of C\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create and train the model\n",
    "model = LogisticRegression(C=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# print the accuracy for the model\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd878c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform xgboost on the dataset\n",
    "import xgboost as xgb\n",
    "\n",
    "# create the DMatrix\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "# create the parameter dictionary\n",
    "params = {'max_depth': 2, 'eta': 1, 'objective': 'binary:logistic'}\n",
    "\n",
    "# train the model\n",
    "num_rounds = 2\n",
    "bst = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "# create the DMatrix for the testing data\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "# make predictions\n",
    "predictions = bst.predict(dtest)\n",
    "\n",
    "# print the first 4 predictions\n",
    "print(predictions[:4])\n",
    "\n",
    "# print the first 4 actual labels\n",
    "print(y_test[:4])\n",
    "\n",
    "# print the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions.round())\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba40d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing a decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# create the model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# print the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Tree accuracy:\", accuracy)\n",
    "\n",
    "#implementing a random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create the model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# print the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Forest accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98164491",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing a gradient boosted tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# create the model\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# print the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Gradient Boosted Tree accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fea2540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a neural network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "activations = ['identity', 'logistic', 'tanh', 'relu']\n",
    "solvers = ['lbfgs', 'sgd', 'adam']\n",
    "\n",
    "# create the model\n",
    "model = MLPClassifier(hidden_layer_sizes=(40, 35, 30, 25), max_iter=500)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Training set accuracy:\", model.score(X_train, y_train))\n",
    "print(f\"Testing accuracy:\", accuracy)\n",
    "\n",
    "#save the model using pickle\n",
    "import pickle\n",
    "\n",
    "s = pickle.dumps(model)\n",
    "saved_model = pickle.loads(s)\n",
    "\n",
    "best_weights=model.coefs_\n",
    "best_biases=model.intercepts_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c38ab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# instantiate the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=400, max_depth=17,min_samples_split=25)\n",
    "\n",
    "# fit the classifier to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# evaluate the accuracy of the model on the testing data\n",
    "accuracy = rf_classifier.score(X_test, y_test)\n",
    "accuracyy = rf_classifier.score(X_train, y_train)\n",
    "\n",
    "print(accuracy)\n",
    "print(accuracyy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b9fc8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 0.7371806663280575\n",
      "Testing accuracy: 0.7301251745653483\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, BatchNormalization \n",
    "from keras import Sequential\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras import regularizers  # Added import for regularizers\n",
    "\n",
    "'''Write your code here'''\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Dense(200, activation='relu'),  # Increased neurons to 128\n",
    "    BatchNormalization(),\n",
    "    Dense(100, activation='relu'),  # Increased neurons to 64\n",
    "    BatchNormalization(),\n",
    "    Dense(28, activation='relu'),  # Increased neurons to 32\n",
    "    BatchNormalization(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model with appropriate loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the test accuracy\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050128a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
